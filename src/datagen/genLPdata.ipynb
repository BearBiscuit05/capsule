{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as MF\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "from dgl.data import AsNodePredDataset\n",
    "from dgl.dataloading import DataLoader, NeighborSampler, MultiLayerFullNeighborSampler\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "import os\n",
    "import numpy as np\n",
    "from dgl.dataloading import (\n",
    "    as_edge_prediction_sampler,\n",
    "    DataLoader,\n",
    "    MultiLayerFullNeighborSampler,\n",
    "    negative_sampler,\n",
    "    NeighborSampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AsNodePredDataset(DglNodePropPredDataset('ogbn-products',root=\"/home/bear/workspace/singleGNN/data/dataset\"))\n",
    "folder_path=\"/home/bear/workspace/singleGNN/data/dataset/ogbn_products/split_lp\"\n",
    "os.makedirs(folder_path)\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products数据集\n",
    "nodeNUM:2449029\n",
    "edgeNUM:123718152\n",
    "feat:100\n",
    "class:47\n",
    "trainNUM:196615\n",
    "valNUM:39323\n",
    "testNUM:2213091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "edgeNUM = 1000000\n",
    "neg_num = 1000\n",
    "sampled_edge_ids = random.sample(range(g.num_edges()), edgeNUM)\n",
    "trainId=sampled_edge_ids[:int(edgeNUM * 0.3)]\n",
    "TestId=sampled_edge_ids[int(edgeNUM * 0.3):int(edgeNUM * 0.9)]\n",
    "ValId=sampled_edge_ids[int(edgeNUM * 0.9):]\n",
    "\n",
    "\n",
    "neg_train_sampler = dgl.dataloading.negative_sampler.Uniform(1)\n",
    "train_src, train_neg_dst = neg_train_sampler(g, torch.Tensor(trainId).to(torch.int64))\n",
    "raw_train_src=torch.Tensor(g.edges()[0][trainId])\n",
    "raw_train_dst=torch.Tensor(g.edges()[1][trainId])\n",
    "\n",
    "\n",
    "neg_val_sampler = dgl.dataloading.negative_sampler.Uniform(neg_num)\n",
    "val_src,val_neg_dst = neg_val_sampler(g, torch.Tensor(ValId).to(torch.int64))\n",
    "raw_val_src=torch.Tensor(g.edges()[0][ValId])\n",
    "raw_val_dst=torch.Tensor(g.edges()[1][ValId])\n",
    "val_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "neg_test_sampler = dgl.dataloading.negative_sampler.Uniform(neg_num)\n",
    "test_src, test_neg_dst = neg_test_sampler(g, torch.Tensor(TestId).to(torch.int64))\n",
    "raw_test_src=torch.Tensor(g.edges()[0][TestId])\n",
    "raw_test_dst=torch.Tensor(g.edges()[1][TestId])\n",
    "test_neg_dst.reshape(-1,neg_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'train': {'source_node': tensor([ 837791,  837791,  837791,  ...,  928474, 1521923, 1257024]),\n",
    "  'target_node': tensor([    102, 1074631, 1658157,  ...,  250277,  316321,  325910])},\n",
    " 'valid': {'source_node': tensor([2302382, 1112061, 1660093,  ..., 1660079, 2395010,   88681]),\n",
    "  'target_node': tensor([ 245742,  839129,  228003,  ...,  699000, 2485204,  849448]),\n",
    "  'target_node_neg': tensor([[2415348,  412967, 2565382,  ..., 1353044, 1652394, 1627182],\n",
    "          ...,\n",
    "          [ 576938, 2577235, 2070601,  ...,  155330, 1643711, 1166252]])},\n",
    " 'test': {'source_node': tensor([2302382, 1112061, 1660093,  ..., 1660079, 2395010,   88681]),\n",
    "  'target_node': tensor([1611317,  963234,  108714,  ..., 2537726,  163858,  112969]),\n",
    "  'target_node_neg': tensor([[ 114076, 2093394, 1308822,  ..., 2321062, 1852878,  936672],\n",
    "          ...,\n",
    "          [2587770, 2587954,   49452,  ..., 1938683, 1319512, 2029363]])}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lp={}\n",
    "split_lp['train']={}\n",
    "split_lp['train']['source_node']=raw_train_src\n",
    "split_lp['train']['target_node']=raw_train_dst\n",
    "split_lp['train']['target_node_neg']=raw_train_src\n",
    "\n",
    "split_lp['valid']={}\n",
    "split_lp['valid']['source_node']=raw_val_src\n",
    "split_lp['valid']['target_node']=raw_val_dst\n",
    "split_lp['valid']['target_node_neg']=val_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "split_lp['test']={}\n",
    "split_lp['test']['source_node']=raw_test_src\n",
    "split_lp['test']['target_node']=raw_test_dst\n",
    "split_lp['test']['target_node_neg']=test_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "split_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = folder_path+\"/split_dict.pt\"\n",
    "torch.save(split_lp, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curDir = \"/home/bear/workspace/singleGNN/src/predata/LP\"\n",
    "def load_reddit(self_loop=True):\n",
    "    from dgl.data import RedditDataset\n",
    "    data = RedditDataset(self_loop=self_loop,raw_dir=curDir+'/../../../data/dataset/')\n",
    "    g = data[0]\n",
    "    g.ndata['feat'] = g.ndata.pop('feat')\n",
    "    g.ndata['label'] = g.ndata.pop('label')\n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    test_idx = []\n",
    "    for index in range(len(g.ndata['train_mask'])):\n",
    "        if g.ndata['train_mask'][index] == 1:\n",
    "            train_idx.append(index)\n",
    "    for index in range(len(g.ndata['val_mask'])):\n",
    "        if g.ndata['val_mask'][index] == 1:\n",
    "            val_idx.append(index)\n",
    "    for index in range(len(g.ndata['test_mask'])):\n",
    "        if g.ndata['test_mask'][index] == 1:\n",
    "            test_idx.append(index)\n",
    "    return g, data,train_idx,val_idx,test_idx\n",
    "\n",
    "g, Testdata , train_idx , val_idx,test_idx = load_reddit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reddit数据集\n",
    "nodeNUM:232965\n",
    "edgeNUM:114848857\n",
    "feat:602\n",
    "class:41\n",
    "trainNUM:153431\n",
    "valNUM:23831\n",
    "testNUM:55703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "edgeNUM = 1000000\n",
    "neg_num = 1000\n",
    "sampled_edge_ids = random.sample(range(g.num_edges()), edgeNUM)\n",
    "trainId=sampled_edge_ids[:int(edgeNUM * 0.3)]\n",
    "TestId=sampled_edge_ids[int(edgeNUM * 0.3):int(edgeNUM * 0.9)]\n",
    "ValId=sampled_edge_ids[int(edgeNUM * 0.9):]\n",
    "\n",
    "\n",
    "neg_train_sampler = dgl.dataloading.negative_sampler.Uniform(1)\n",
    "train_src, train_neg_dst = neg_train_sampler(g, torch.Tensor(trainId).to(torch.int64))\n",
    "raw_train_src=torch.Tensor(g.edges()[0][trainId])\n",
    "raw_train_dst=torch.Tensor(g.edges()[1][trainId])\n",
    "\n",
    "\n",
    "neg_val_sampler = dgl.dataloading.negative_sampler.Uniform(neg_num)\n",
    "val_src,val_neg_dst = neg_val_sampler(g, torch.Tensor(ValId).to(torch.int64))\n",
    "raw_val_src=torch.Tensor(g.edges()[0][ValId])\n",
    "raw_val_dst=torch.Tensor(g.edges()[1][ValId])\n",
    "val_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "neg_test_sampler = dgl.dataloading.negative_sampler.Uniform(neg_num)\n",
    "test_src, test_neg_dst = neg_test_sampler(g, torch.Tensor(TestId).to(torch.int64))\n",
    "raw_test_src=torch.Tensor(g.edges()[0][TestId])\n",
    "raw_test_dst=torch.Tensor(g.edges()[1][TestId])\n",
    "test_neg_dst.reshape(-1,neg_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lp={}\n",
    "split_lp['train']={}\n",
    "split_lp['train']['source_node']=raw_train_src\n",
    "split_lp['train']['target_node']=raw_train_dst\n",
    "split_lp['train']['target_node_neg']=raw_train_src\n",
    "\n",
    "split_lp['valid']={}\n",
    "split_lp['valid']['source_node']=raw_val_src\n",
    "split_lp['valid']['target_node']=raw_val_dst\n",
    "split_lp['valid']['target_node_neg']=val_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "split_lp['test']={}\n",
    "split_lp['test']['source_node']=raw_test_src\n",
    "split_lp['test']['target_node']=raw_test_dst\n",
    "split_lp['test']['target_node_neg']=test_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "split_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=curDir+'/../../../data/dataset/split_lp'\n",
    "os.makedirs(folder_path)\n",
    "file_name = folder_path+\"/split_dict.pt\"\n",
    "torch.save(split_lp, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "papers100M\n",
    "NUM_NODE 111059956\n",
    "NUM_EDGE 1615685872\n",
    "FEAT_DIM 128\n",
    "NUM_CLASS 172\n",
    "NUM_TRAIN_SET 1207179\n",
    "NUM_VALID_SET 125265\n",
    "NUM_TEST_SET 214338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AsNodePredDataset(DglNodePropPredDataset('ogbn-papers100M',root=\"/home/bear/workspace/singleGNN/data/dataset\"))\n",
    "folder_path=\"/home/bear/workspace/singleGNN/data/dataset/ogbn_papers100M/split_lp\"\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 87620217,  22726618,  15540116,  ...,  76645077,  51637092,\n",
       "           9141623],\n",
       "        [ 79609988, 106562796,  19031938,  ...,  45179732,  29489313,\n",
       "          68262324],\n",
       "        [ 67615131,  35122358,  31534095,  ...,  23537764,  46582316,\n",
       "           6081263],\n",
       "        ...,\n",
       "        [102118730,  77078689,   5636326,  ...,  73862778, 110919615,\n",
       "          84306357],\n",
       "        [ 26775461, 102668199,  26527095,  ...,   6439139,  95580728,\n",
       "          39720208],\n",
       "        [101741270,  72419540,  50289590,  ...,  89388958,  57707276,\n",
       "          69523028]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "edgeNUM = 1000000\n",
    "neg_num = 1000\n",
    "sampled_edge_ids = random.sample(range(g.num_edges()), edgeNUM)\n",
    "trainId=sampled_edge_ids[:int(edgeNUM * 0.7)]\n",
    "TestId=sampled_edge_ids[int(edgeNUM * 0.7):int(edgeNUM * 0.8)]\n",
    "ValId=sampled_edge_ids[int(edgeNUM * 0.8):]\n",
    "\n",
    "\n",
    "neg_train_sampler = dgl.dataloading.negative_sampler.Uniform(1)\n",
    "train_src, train_neg_dst = neg_train_sampler(g, torch.Tensor(trainId).to(torch.int64))\n",
    "raw_train_src=torch.Tensor(g.edges()[0][trainId])\n",
    "raw_train_dst=torch.Tensor(g.edges()[1][trainId])\n",
    "\n",
    "\n",
    "neg_val_sampler = dgl.dataloading.negative_sampler.Uniform(neg_num)\n",
    "val_src,val_neg_dst = neg_val_sampler(g, torch.Tensor(ValId).to(torch.int64))\n",
    "raw_val_src=torch.Tensor(g.edges()[0][ValId])\n",
    "raw_val_dst=torch.Tensor(g.edges()[1][ValId])\n",
    "val_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "neg_test_sampler = dgl.dataloading.negative_sampler.Uniform(neg_num)\n",
    "test_src, test_neg_dst = neg_test_sampler(g, torch.Tensor(TestId).to(torch.int64))\n",
    "raw_test_src=torch.Tensor(g.edges()[0][TestId])\n",
    "raw_test_dst=torch.Tensor(g.edges()[1][TestId])\n",
    "test_neg_dst.reshape(-1,neg_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'source_node': tensor([ 74899120,  28935318, 108993319,  ...,  17725672,  51295747,\n",
       "           11235088]),\n",
       "  'target_node': tensor([110309000,  17422069,  43173260,  ...,  41836426,  48846544,\n",
       "           54198778]),\n",
       "  'target_node_neg': tensor([ 74899120,  28935318, 108993319,  ...,  17725672,  51295747,\n",
       "           11235088])},\n",
       " 'valid': {'source_node': tensor([30358606, 49683980, 85968075,  ..., 43409525, 12644410, 49858950]),\n",
       "  'target_node': tensor([75882512, 17635722, 48179337,  ..., 41169108, 49588762, 11301133]),\n",
       "  'target_node_neg': tensor([[  2952144,  78265132,  29464046,  ...,  28026378,  16457940,\n",
       "            79767986],\n",
       "          [ 58115494,  29845485,  61869358,  ..., 101533473,  62539791,\n",
       "            74905925],\n",
       "          [ 89803842, 103073473, 108021274,  ...,  45359929,  87585498,\n",
       "            34878425],\n",
       "          ...,\n",
       "          [ 19339989,  34061348,  76698551,  ...,  64804734,  59888454,\n",
       "            87020921],\n",
       "          [ 26682967,  88971997,  39994237,  ...,  70666993,  92758259,\n",
       "            39746161],\n",
       "          [ 51363197,  62786499,  74915860,  ..., 100726505,  85582947,\n",
       "            40623545]])},\n",
       " 'test': {'source_node': tensor([ 45278258, 101897976,  74556038,  ...,  79613490,  73079198,\n",
       "          109814079]),\n",
       "  'target_node': tensor([24453439, 85232276, 50161961,  ..., 32757391, 85590821, 22987618]),\n",
       "  'target_node_neg': tensor([[ 87620217,  22726618,  15540116,  ...,  76645077,  51637092,\n",
       "             9141623],\n",
       "          [ 79609988, 106562796,  19031938,  ...,  45179732,  29489313,\n",
       "            68262324],\n",
       "          [ 67615131,  35122358,  31534095,  ...,  23537764,  46582316,\n",
       "             6081263],\n",
       "          ...,\n",
       "          [102118730,  77078689,   5636326,  ...,  73862778, 110919615,\n",
       "            84306357],\n",
       "          [ 26775461, 102668199,  26527095,  ...,   6439139,  95580728,\n",
       "            39720208],\n",
       "          [101741270,  72419540,  50289590,  ...,  89388958,  57707276,\n",
       "            69523028]])}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_lp={}\n",
    "split_lp['train']={}\n",
    "split_lp['train']['source_node']=raw_train_src\n",
    "split_lp['train']['target_node']=raw_train_dst\n",
    "split_lp['train']['target_node_neg']=raw_train_src\n",
    "\n",
    "split_lp['valid']={}\n",
    "split_lp['valid']['source_node']=raw_val_src\n",
    "split_lp['valid']['target_node']=raw_val_dst\n",
    "split_lp['valid']['target_node_neg']=val_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "split_lp['test']={}\n",
    "split_lp['test']['source_node']=raw_test_src\n",
    "split_lp['test']['target_node']=raw_test_dst\n",
    "split_lp['test']['target_node_neg']=test_neg_dst.reshape(-1,neg_num)\n",
    "\n",
    "split_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "file_name = folder_path+\"/split_dict.pt\"\n",
    "torch.save(split_lp, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
