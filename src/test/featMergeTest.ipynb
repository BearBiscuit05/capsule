{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bear/miniconda3/envs/dgl_v09/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featAdd 0.0390s\n",
      "memfeat: tensor([-1, 20, 26, 21,  8,  9, 10])\n",
      "cudafeat: tensor([-1, 24, 22, 25, 23, 15, 16], device='cuda:0')\n",
      "addfeat: tensor([20, 21, 22, 23, 24, 25, 26])\n"
     ]
    }
   ],
   "source": [
    "def featAdd(addIdx, addfeat, memfeat, cudafeat):\n",
    "    # Convert addFeat, but you need to pay attention to the separate conversion of mem and cuda two feat vectors\n",
    "    # Total can be considered as feat[addIdx] = addfeat\n",
    "    # Split memfeat[addIdx_mem] = addfeat_mem; cudafeat[addIdx_cuda] = addfeat_cuda\n",
    "    # Here addIdx has been converted to the actual index location via map\n",
    "    start = time.time()\n",
    "    addIdx = addIdx.cuda()\n",
    "\n",
    "    addIdx_mem_indice = torch.nonzero(addIdx < 0).reshape(-1)\n",
    "    addIdx_cuda_indice = torch.nonzero(addIdx > 0).reshape(-1)\n",
    "\n",
    "    addIdx_mem = addIdx[addIdx_mem_indice] * (-1)\n",
    "    addIdx_cuda = addIdx[addIdx_cuda_indice]\n",
    "    \n",
    "    # a bit slow\n",
    "    memfeat[addIdx_mem] = addfeat[addIdx_mem_indice]\n",
    "    cudafeat[addIdx_cuda] = addfeat[addIdx_cuda_indice].cuda()\n",
    "\n",
    "    print(f\"featAdd {time.time() - start:.4f}s\")\n",
    "\n",
    "#test:\n",
    "addIdx = torch.tensor([-1,-3,2,4,1,3,-2])\n",
    "memfeat = torch.tensor([-1,5,6,7,8,9,10])\n",
    "cudafeat = torch.tensor([-1,11,12,13,14,15,16]).cuda()\n",
    "addfeat = torch.tensor([20,21,22,23,24,25,26])\n",
    "featAdd(addIdx, addfeat, memfeat,cudafeat)\n",
    "print(\"memfeat:\",memfeat)\n",
    "print(\"cudafeat:\",cudafeat)\n",
    "print(\"addfeat:\",addfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cac(lossMap, feat, memfeat, cudafeat, map):\n",
    "    #Migrate feat initialization to memfeat and cudafeat\n",
    "    mask = torch.ones(lossMap.shape[0], dtype = torch.bool, device='cuda')\n",
    "    mask[lossMap == -1] = False\n",
    "\n",
    "    cutfeat = feat[~mask]\n",
    "    memfeat[1 : cutfeat.shape[0] + 1] = cutfeat\n",
    "    map[~mask] = (-1) * torch.arange(1, cutfeat.shape[0] + 1, device = 'cuda', dtype=torch.int64)\n",
    "\n",
    "    savefeat = feat[mask]\n",
    "    cudafeat[1 :savefeat.shape[0] + 1] = savefeat\n",
    "    map[mask] = torch.arange(1, savefeat.shape[0] + 1, device = 'cuda', dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)\n",
      "tensor([-2, -3, -4], dtype=torch.int32)\n",
      "tensor([ 0,  1,  2,  3,  4, -2, -3, -4,  8,  9], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.zeros(10, dtype = torch.bool)\n",
    "mask[5:8] = True\n",
    "table = torch.arange(10,dtype = torch.int32)\n",
    "\n",
    "addFeat = torch.Tensor([-2,-3,-4]).to(torch.int32)\n",
    "print(table)\n",
    "print(addFeat)\n",
    "table[mask]=addFeat\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_feat_cac 0.0008s\n",
      "memfeat : tensor([-1, 23, 24, 13, 25, 26])\n",
      "cudafeat: tensor([-1, 21, 22, 11, 12, 14, 15, 27], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#cuda and cpu convert\n",
    "def loss_feat_cac(lossMap, memfeat, cudafeat, map):\n",
    "    # Calling this function requires guarantees\n",
    "    #1.memfeat and cudafeat contain the feat of all the current subgraphs (can have redundant feat but must have all)\n",
    "    #2.lossMap stores node index, and map functions as node index -> memfeat/cudafeat index\n",
    "    # Function: cudafeat all feat of all current graph nodes that are not lost, and update map\n",
    "    # That is, swap the locations of non-Savenode nodes in cudafeat and saveNode nodes in memfeat and maintain map\n",
    "    # Ensure: Number of non-Savenode nodes in cudafeat > Number of saveNode nodes in memfeat\n",
    "    start = time.time()\n",
    "    saveNode = torch.nonzero(lossMap != -1).reshape(-1)\n",
    "\n",
    "    # get saveNode\n",
    "    saveIdxMap_mem = saveNode[torch.nonzero(map[saveNode] < 0).reshape(-1)]\n",
    "    saveIdx_mem = map[saveIdxMap_mem] * (-1)\n",
    "\n",
    "    # Gets the non-save index in cuda\n",
    "    mask = torch.ones(map.shape[0], dtype=torch.bool, device='cuda')\n",
    "    mask[saveNode] = False\n",
    "    mask[torch.nonzero(map < 0).reshape(-1)] = False\n",
    "    nsaveMap_cuda = (torch.nonzero(mask).reshape(-1))[:saveIdx_mem.shape[0]]\n",
    "    nsaveIdx_cuda = map[nsaveMap_cuda]\n",
    "\n",
    "    # Swap nsave_cuda[:len(save_mem)] with save_mem and maintain map\n",
    "    cuda_tmp = cudafeat[nsaveIdx_cuda]\n",
    "    cudafeat[nsaveIdx_cuda] = memfeat[saveIdx_mem].cuda()\n",
    "    memfeat[saveIdx_mem] = cuda_tmp.cpu()\n",
    "\n",
    "    # Maintaining map\n",
    "    map_cuda_tmp = map[nsaveMap_cuda]\n",
    "    map[nsaveMap_cuda] = map[saveIdxMap_mem]\n",
    "    map[saveIdxMap_mem] = map_cuda_tmp\n",
    "    print(f\"loss_feat_cac {time.time() - start:.4f}s\")\n",
    "\n",
    "#test:\n",
    "map = torch.tensor([-1,-2,1,2,3,-3,-4,-5,4,5,6])\n",
    "lossMap = torch.tensor([1,1,1,1,-1,-1,1,1])\n",
    "memfeat = torch.tensor([-1,11,12,13,14,15])\n",
    "cudafeat = torch.tensor([-1,21,22,23,24,25,26,27]).cuda()\n",
    "loss_feat_cac(lossMap,memfeat,cudafeat,map)\n",
    "print(\"memfeat :\",memfeat)\n",
    "print(\"cudafeat:\",cudafeat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl_v09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
