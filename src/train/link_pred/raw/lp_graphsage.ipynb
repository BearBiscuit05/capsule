{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from dgl.dataloading import (\n",
    "    as_edge_prediction_sampler,\n",
    "    DataLoader,\n",
    "    MultiLayerFullNeighborSampler,\n",
    "    negative_sampler,\n",
    "    NeighborSampler,\n",
    ")\n",
    "from ogb.linkproppred import DglLinkPropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bidirected_with_reverse_mapping(g):\n",
    "    g_simple, mapping = dgl.to_simple(\n",
    "        dgl.add_reverse_edges(g), return_counts=\"count\", writeback_mapping=True\n",
    "    )\n",
    "    c = g_simple.edata[\"count\"]\n",
    "    num_edges = g.num_edges()\n",
    "    mapping_offset = torch.zeros(\n",
    "        g_simple.num_edges() + 1, dtype=g_simple.idtype\n",
    "    )\n",
    "    mapping_offset[1:] = c.cumsum(0)\n",
    "    idx = mapping.argsort()\n",
    "    idx_uniq = idx[mapping_offset[:-1]]\n",
    "    reverse_idx = torch.where(\n",
    "        idx_uniq >= num_edges, idx_uniq - num_edges, idx_uniq + num_edges\n",
    "    )\n",
    "    reverse_mapping = mapping[reverse_idx]\n",
    "    src1, dst1 = g_simple.edges()\n",
    "    src2, dst2 = g_simple.find_edges(reverse_mapping)\n",
    "    assert torch.equal(src1, dst2)\n",
    "    assert torch.equal(src2, dst1)\n",
    "    return g_simple, reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_size, hid_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        # three-layer GraphSAGE-mean\n",
    "        self.layers.append(dglnn.SAGEConv(in_size, hid_size, \"mean\"))\n",
    "        self.layers.append(dglnn.SAGEConv(hid_size, hid_size, \"mean\"))\n",
    "        self.layers.append(dglnn.SAGEConv(hid_size, hid_size, \"mean\"))\n",
    "        self.hid_size = hid_size\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hid_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, pair_graph, neg_pair_graph, blocks, x):\n",
    "        h = x\n",
    "        for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
    "            h = layer(block, h)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = F.relu(h)\n",
    "        pos_src, pos_dst = pair_graph.edges()\n",
    "        neg_src, neg_dst = neg_pair_graph.edges()\n",
    "        h_pos = self.predictor(h[pos_src] * h[pos_dst])\n",
    "        h_neg = self.predictor(h[neg_src] * h[neg_dst])\n",
    "        return h_pos, h_neg\n",
    "\n",
    "    def inference(self, g, device, batch_size):\n",
    "        \"\"\"Layer-wise inference algorithm to compute GNN node embeddings.\"\"\"\n",
    "        feat = g.ndata[\"feat\"]\n",
    "        sampler = MultiLayerFullNeighborSampler(1, prefetch_node_feats=[\"feat\"])\n",
    "        dataloader = DataLoader(\n",
    "            g,\n",
    "            torch.arange(g.num_nodes()).to(g.device),\n",
    "            sampler,\n",
    "            device=device,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=0,\n",
    "        )\n",
    "        buffer_device = torch.device(\"cpu\")\n",
    "        pin_memory = buffer_device != device\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            y = torch.empty(\n",
    "                g.num_nodes(),\n",
    "                self.hid_size,\n",
    "                device=buffer_device,\n",
    "                pin_memory=pin_memory,\n",
    "            )\n",
    "            feat = feat.to(device)\n",
    "            for input_nodes, output_nodes, blocks in tqdm.tqdm(\n",
    "                dataloader, desc=\"Inference\"\n",
    "            ):\n",
    "                x = feat[input_nodes]\n",
    "                h = layer(blocks[0], x)\n",
    "                if l != len(self.layers) - 1:\n",
    "                    h = F.relu(h)\n",
    "                y[output_nodes] = h.to(buffer_device)\n",
    "            feat = y\n",
    "        return y\n",
    "\n",
    "\n",
    "def compute_mrr(\n",
    "    model, evaluator, node_emb, src, dst, neg_dst, device, batch_size=500\n",
    "):\n",
    "    \"\"\"Compute Mean Reciprocal Rank (MRR) in batches.\"\"\"\n",
    "    rr = torch.zeros(src.shape[0])\n",
    "    for start in tqdm.trange(0, src.shape[0], batch_size, desc=\"Evaluate\"):\n",
    "        end = min(start + batch_size, src.shape[0])\n",
    "        all_dst = torch.cat([dst[start:end, None], neg_dst[start:end]], 1)\n",
    "        h_src = node_emb[src[start:end]][:, None, :].to(device)\n",
    "        h_dst = node_emb[all_dst.view(-1)].view(*all_dst.shape, -1).to(device)\n",
    "        pred = model.predictor(h_src * h_dst).squeeze(-1)\n",
    "        input_dict = {\"y_pred_pos\": pred[:, 0], \"y_pred_neg\": pred[:, 1:]}\n",
    "        rr[start:end] = evaluator.eval(input_dict)[\"mrr_list\"]\n",
    "    return rr.mean()\n",
    "\n",
    "\n",
    "def evaluate(device, graph, edge_split, model, batch_size):\n",
    "    model.eval()\n",
    "    evaluator = Evaluator(name=\"ogbl-citation2\")\n",
    "    with torch.no_grad():\n",
    "        node_emb = model.inference(graph, device, batch_size)\n",
    "        results = []\n",
    "        for split in [\"valid\", \"test\"]:\n",
    "            src = edge_split[split][\"source_node\"].to(node_emb.device)\n",
    "            dst = edge_split[split][\"target_node\"].to(node_emb.device)\n",
    "            neg_dst = edge_split[split][\"target_node_neg\"].to(node_emb.device)\n",
    "            results.append(\n",
    "                compute_mrr(\n",
    "                    model, evaluator, node_emb, src, dst, neg_dst, device\n",
    "                )\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DglLinkPropPredDataset(\"ogbl-citation2\",root=\"/raid/bear/raw_dataset\")\n",
    "#dataset = DglLinkPropPredDataset(\"ogbl-ppa\",root=\"/raid/bear/raw_dataset\")\n",
    "#dataset = DglLinkPropPredDataset(\"ogbl-vessel\",root=\"/raid/bear/raw_dataset\")\n",
    "g = dataset[0]\n",
    "g, reverse_eids = to_bidirected_with_reverse_mapping(g)\n",
    "edge_split = dataset.get_edge_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2927963, num_edges=60703760,\n",
       "      ndata_schemes={'year': Scheme(shape=(1,), dtype=torch.int64), 'feat': Scheme(shape=(128,), dtype=torch.float32)}\n",
       "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, g, reverse_eids, seed_edges, model):\n",
    "    # create sampler & dataloader\n",
    "    sampler = NeighborSampler([5, 5, 5], prefetch_node_feats=[\"feat\"])\n",
    "    sampler = as_edge_prediction_sampler(\n",
    "        sampler,\n",
    "        exclude=\"reverse_id\",\n",
    "        reverse_eids=reverse_eids,\n",
    "        negative_sampler=negative_sampler.Uniform(1),\n",
    "    )\n",
    "    use_uva = True\n",
    "    dataloader = DataLoader(\n",
    "        g,\n",
    "        seed_edges,\n",
    "        sampler,\n",
    "        device=device,\n",
    "        batch_size=512,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=0,\n",
    "        use_uva=use_uva,\n",
    "    )\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for it, (input_nodes, pair_graph, neg_pair_graph, blocks) in enumerate(\n",
    "            dataloader\n",
    "        ):\n",
    "            x = blocks[0].srcdata[\"feat\"]\n",
    "            pos_score, neg_score = model(pair_graph, neg_pair_graph, blocks, x)\n",
    "            score = torch.cat([pos_score, neg_score])\n",
    "            pos_label = torch.ones_like(pos_score)\n",
    "            neg_label = torch.zeros_like(neg_score)\n",
    "            labels = torch.cat([pos_label, neg_label])\n",
    "            loss = F.binary_cross_entropy_with_logits(score, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "            if (it + 1) == 1000:\n",
    "                break\n",
    "        print(\"Epoch {:05d} | Loss {:.4f}\".format(epoch, total_loss / (it + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Training...\n",
      "Epoch 00000 | Loss 0.1495\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb 单元格 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# model training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m train(device, g, reverse_eids, seed_edges, model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# validate/test the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation/Testing...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb 单元格 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m it, (input_nodes, pair_graph, neg_pair_graph, blocks) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     dataloader\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m ):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     x \u001b[39m=\u001b[39m blocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msrcdata[\u001b[39m\"\u001b[39m\u001b[39mfeat\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2241313030227d/home/bear/workspace/singleGNN/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     pos_score, neg_score \u001b[39m=\u001b[39m model(pair_graph, neg_pair_graph, blocks, x)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/dataloading/dataloader.py:619\u001b[0m, in \u001b[0;36m_PrefetchingIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    618\u001b[0m     batch, feats, stream_event \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_non_threaded()\n\u001b[1;32m    620\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_thread\n\u001b[1;32m    621\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_threaded()\n\u001b[1;32m    622\u001b[0m     )\n\u001b[1;32m    623\u001b[0m     batch \u001b[39m=\u001b[39m recursive_apply_pair(batch, feats, _assign_for)\n\u001b[1;32m    624\u001b[0m     \u001b[39mif\u001b[39;00m stream_event \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/dataloading/dataloader.py:592\u001b[0m, in \u001b[0;36m_PrefetchingIter._next_non_threaded\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_non_threaded\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 592\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader_it)\n\u001b[1;32m    593\u001b[0m     batch \u001b[39m=\u001b[39m recursive_apply(\n\u001b[1;32m    594\u001b[0m         batch, restore_parent_storage_columns, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader\u001b[39m.\u001b[39mgraph\n\u001b[1;32m    595\u001b[0m     )\n\u001b[1;32m    596\u001b[0m     batch, feats, stream_event \u001b[39m=\u001b[39m _prefetch(\n\u001b[1;32m    597\u001b[0m         batch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream\n\u001b[1;32m    598\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:40\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_iter)\n\u001b[0;32m---> 40\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/dataloading/dataloader.py:647\u001b[0m, in \u001b[0;36mCollateWrapper.__call__\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_uva \u001b[39mor\u001b[39;00m (graph_device \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    644\u001b[0m     \u001b[39m# Only copy the indices to the given device if in UVA mode or the graph\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     \u001b[39m# is not on CPU.\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     items \u001b[39m=\u001b[39m recursive_apply(items, \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n\u001b[0;32m--> 647\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mg, items)\n\u001b[1;32m    648\u001b[0m \u001b[39mreturn\u001b[39;00m recursive_apply(batch, remove_parent_storage_columns, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/dataloading/base.py:488\u001b[0m, in \u001b[0;36mEdgePredictionSampler.sample\u001b[0;34m(self, g, seed_edges)\u001b[0m\n\u001b[1;32m    477\u001b[0m seed_nodes \u001b[39m=\u001b[39m pair_graph\u001b[39m.\u001b[39mndata[NID]\n\u001b[1;32m    479\u001b[0m exclude_eids \u001b[39m=\u001b[39m find_exclude_eids(\n\u001b[1;32m    480\u001b[0m     g,\n\u001b[1;32m    481\u001b[0m     seed_edges,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device,\n\u001b[1;32m    486\u001b[0m )\n\u001b[0;32m--> 488\u001b[0m input_nodes, _, blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampler\u001b[39m.\u001b[39;49msample(\n\u001b[1;32m    489\u001b[0m     g, seed_nodes, exclude_eids\n\u001b[1;32m    490\u001b[0m )\n\u001b[1;32m    492\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnegative_sampler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massign_lazy_features((input_nodes, pair_graph, blocks))\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/dataloading/base.py:260\u001b[0m, in \u001b[0;36mBlockSampler.sample\u001b[0;34m(self, g, seed_nodes, exclude_eids)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample\u001b[39m(\n\u001b[1;32m    257\u001b[0m     \u001b[39mself\u001b[39m, g, seed_nodes, exclude_eids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m ):  \u001b[39m# pylint: disable=arguments-differ\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sample a list of blocks from the given seed nodes.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_blocks(g, seed_nodes, exclude_eids\u001b[39m=\u001b[39;49mexclude_eids)\n\u001b[1;32m    261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massign_lazy_features(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/dataloading/neighbor_sampler.py:145\u001b[0m, in \u001b[0;36mNeighborSampler.sample_blocks\u001b[0;34m(self, g, seed_nodes, exclude_eids)\u001b[0m\n\u001b[1;32m    143\u001b[0m blocks \u001b[39m=\u001b[39m []\n\u001b[1;32m    144\u001b[0m \u001b[39mfor\u001b[39;00m fanout \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfanouts):\n\u001b[0;32m--> 145\u001b[0m     frontier \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49msample_neighbors(\n\u001b[1;32m    146\u001b[0m         seed_nodes,\n\u001b[1;32m    147\u001b[0m         fanout,\n\u001b[1;32m    148\u001b[0m         edge_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_dir,\n\u001b[1;32m    149\u001b[0m         prob\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprob,\n\u001b[1;32m    150\u001b[0m         replace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplace,\n\u001b[1;32m    151\u001b[0m         output_device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_device,\n\u001b[1;32m    152\u001b[0m         exclude_edges\u001b[39m=\u001b[39;49mexclude_eids,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     eid \u001b[39m=\u001b[39m frontier\u001b[39m.\u001b[39medata[EID]\n\u001b[1;32m    155\u001b[0m     block \u001b[39m=\u001b[39m to_block(frontier, seed_nodes)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/utils/internal.py:1051\u001b[0m, in \u001b[0;36malias_func.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m   1050\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/sampling/neighbor.py:382\u001b[0m, in \u001b[0;36msample_neighbors\u001b[0;34m(g, nodes, fanout, edge_dir, prob, replace, copy_ndata, copy_edata, _dist_training, exclude_edges, output_device)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m exclude_edges \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m         eid_excluder \u001b[39m=\u001b[39m EidExcluder(exclude_edges)\n\u001b[0;32m--> 382\u001b[0m         frontier \u001b[39m=\u001b[39m eid_excluder(frontier)\n\u001b[1;32m    383\u001b[0m \u001b[39mreturn\u001b[39;00m frontier \u001b[39mif\u001b[39;00m output_device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m frontier\u001b[39m.\u001b[39mto(output_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/sampling/utils.py:75\u001b[0m, in \u001b[0;36mEidExcluder.__call__\u001b[0;34m(self, frontier, weights)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(located_eids, Mapping):\n\u001b[1;32m     70\u001b[0m     \u001b[39m# (BarclayII) If frontier already has a EID field and located_eids is empty,\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[39m# the returned graph will keep EID intact.  Otherwise, EID will change\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[39m# to the mapping from the new graph to the old frontier.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[39m# So we need to test if located_eids is empty, and do the remapping ourselves.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(located_eids) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m         frontier \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39;49mremove_edges(\n\u001b[1;32m     76\u001b[0m             frontier, located_eids, store_ids\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     79\u001b[0m             weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     80\u001b[0m             \u001b[39mand\u001b[39;00m weights[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m frontier\u001b[39m.\u001b[39mnum_edges()\n\u001b[1;32m     81\u001b[0m         ):\n\u001b[1;32m     82\u001b[0m             weights[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mgather_row(weights[\u001b[39m0\u001b[39m], frontier\u001b[39m.\u001b[39medata[EID])\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/transforms/functional.py:1818\u001b[0m, in \u001b[0;36mremove_edges\u001b[0;34m(g, eids, etype, store_ids)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Remove the specified edges and return a new graph.\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m \n\u001b[1;32m   1750\u001b[0m \u001b[39mAlso delete the features of the edges. The edges must exist in the graph.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[39mremove_nodes\u001b[39;00m\n\u001b[1;32m   1816\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m g \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mclone()\n\u001b[0;32m-> 1818\u001b[0m g\u001b[39m.\u001b[39;49mremove_edges(eids, etype\u001b[39m=\u001b[39;49metype, store_ids\u001b[39m=\u001b[39;49mstore_ids)\n\u001b[1;32m   1819\u001b[0m \u001b[39mreturn\u001b[39;00m g\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/heterograph.py:730\u001b[0m, in \u001b[0;36mDGLGraph.remove_edges\u001b[0;34m(self, eids, etype, store_ids)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39mif\u001b[39;00m c_etype \u001b[39m==\u001b[39m (u_type, e_type, v_type):\n\u001b[1;32m    729\u001b[0m     origin_eids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medges(form\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meid\u001b[39m\u001b[39m\"\u001b[39m, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meid\u001b[39m\u001b[39m\"\u001b[39m, etype\u001b[39m=\u001b[39mc_etype)\n\u001b[0;32m--> 730\u001b[0m     edges[c_etype] \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mcompensate(eids, origin_eids)\n\u001b[1;32m    731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     edges[c_etype] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medges(\n\u001b[1;32m    733\u001b[0m         form\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meid\u001b[39m\u001b[39m\"\u001b[39m, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meid\u001b[39m\u001b[39m\"\u001b[39m, etype\u001b[39m=\u001b[39mc_etype\n\u001b[1;32m    734\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/utils/internal.py:790\u001b[0m, in \u001b[0;36mcompensate\u001b[0;34m(ids, origin_ids)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"computing the compensate set of ids from origin_ids\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \n\u001b[1;32m    777\u001b[0m \u001b[39mNote: ids should be a subset of origin_ids.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[39mth.Tensor([1, 5])\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[39m# trick here, eid_0 or nid_0 can be 0.\u001b[39;00m\n\u001b[1;32m    788\u001b[0m mask \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mscatter_row(\n\u001b[1;32m    789\u001b[0m     origin_ids,\n\u001b[0;32m--> 790\u001b[0m     F\u001b[39m.\u001b[39;49mcopy_to(F\u001b[39m.\u001b[39;49mtensor(\u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mF\u001b[39m.\u001b[39;49mint64), F\u001b[39m.\u001b[39;49mcontext(origin_ids)),\n\u001b[1;32m    791\u001b[0m     F\u001b[39m.\u001b[39mcopy_to(\n\u001b[1;32m    792\u001b[0m         F\u001b[39m.\u001b[39mtensor(\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mF\u001b[39m.\u001b[39mdtype(origin_ids)), F\u001b[39m.\u001b[39mcontext(origin_ids)\n\u001b[1;32m    793\u001b[0m     ),\n\u001b[1;32m    794\u001b[0m )\n\u001b[1;32m    795\u001b[0m mask \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mscatter_row(\n\u001b[1;32m    796\u001b[0m     mask, ids, F\u001b[39m.\u001b[39mfull_1d(\u001b[39mlen\u001b[39m(ids), \u001b[39m0\u001b[39m, F\u001b[39m.\u001b[39mdtype(ids), F\u001b[39m.\u001b[39mcontext(ids))\n\u001b[1;32m    797\u001b[0m )\n\u001b[1;32m    798\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mtensor(F\u001b[39m.\u001b[39mnonzero_1d(mask), dtype\u001b[39m=\u001b[39mF\u001b[39m.\u001b[39mdtype(ids))\n",
      "File \u001b[0;32m~/miniconda3/envs/graphtest/lib/python3.8/site-packages/dgl/backend/pytorch/tensor.py:142\u001b[0m, in \u001b[0;36mcopy_to\u001b[0;34m(input, ctx, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m ctx\u001b[39m.\u001b[39mindex \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m         th\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mset_device(ctx\u001b[39m.\u001b[39mindex)\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mcuda(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid context\u001b[39m\u001b[39m\"\u001b[39m, ctx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\n",
    "#     \"--mode\",\n",
    "#     default=\"mixed\",\n",
    "#     choices=[\"cpu\", \"mixed\", \"puregpu\"],\n",
    "#     help=\"Training mode. 'cpu' for CPU training, 'mixed' for CPU-GPU mixed training, \"\n",
    "#     \"'puregpu' for pure-GPU training.\",\n",
    "# )\n",
    "# args = parser.parse_args()\n",
    "# if not torch.cuda.is_available():\n",
    "#     args.mode = \"cpu\"\n",
    "# print(f\"Training in {args.mode} mode.\")\n",
    "\n",
    "# load and preprocess dataset\n",
    "print(\"Loading data\")\n",
    "dataset = DglLinkPropPredDataset(\"ogbl-citation2\",root=\"/home/bear/workspace/singleGNN/data/dataset\")\n",
    "g = dataset[0]\n",
    "g = g.to(\"cpu\")\n",
    "\n",
    "# print(g.edges())\n",
    "# exit()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "g, reverse_eids = to_bidirected_with_reverse_mapping(g)\n",
    "reverse_eids = reverse_eids.to(device)\n",
    "seed_edges = torch.arange(g.num_edges()).to(device)\n",
    "edge_split = dataset.get_edge_split()\n",
    "\n",
    "# create GraphSAGE model\n",
    "in_size = g.ndata[\"feat\"].shape[1]\n",
    "model = SAGE(in_size, 256).to(device)\n",
    "\n",
    "# model training\n",
    "print(\"Training...\")\n",
    "train(device, g, reverse_eids, seed_edges, model)\n",
    "\n",
    "# validate/test the model\n",
    "print(\"Validation/Testing...\")\n",
    "valid_mrr, test_mrr = evaluate(\n",
    "    device, g, edge_split, model, batch_size=1000\n",
    ")\n",
    "print(\n",
    "    \"Validation MRR {:.4f}, Test MRR {:.4f}\".format(\n",
    "        valid_mrr.item(), test_mrr.item()\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
