{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from dgl.dataloading import (\n",
    "    as_edge_prediction_sampler,\n",
    "    DataLoader,\n",
    "    MultiLayerFullNeighborSampler,\n",
    "    negative_sampler,\n",
    "    NeighborSampler,\n",
    ")\n",
    "from ogb.linkproppred import DglLinkPropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bidirected_with_reverse_mapping(g):\n",
    "    g_simple, mapping = dgl.to_simple(\n",
    "        dgl.add_reverse_edges(g), return_counts=\"count\", writeback_mapping=True\n",
    "    )\n",
    "    c = g_simple.edata[\"count\"]\n",
    "    num_edges = g.num_edges()\n",
    "    mapping_offset = torch.zeros(\n",
    "        g_simple.num_edges() + 1, dtype=g_simple.idtype\n",
    "    )\n",
    "    mapping_offset[1:] = c.cumsum(0)\n",
    "    idx = mapping.argsort()\n",
    "    idx_uniq = idx[mapping_offset[:-1]]\n",
    "    reverse_idx = torch.where(\n",
    "        idx_uniq >= num_edges, idx_uniq - num_edges, idx_uniq + num_edges\n",
    "    )\n",
    "    reverse_mapping = mapping[reverse_idx]\n",
    "    src1, dst1 = g_simple.edges()\n",
    "    src2, dst2 = g_simple.find_edges(reverse_mapping)\n",
    "    assert torch.equal(src1, dst2)\n",
    "    assert torch.equal(src2, dst1)\n",
    "    return g_simple, reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_size, hid_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        # three-layer GraphSAGE-mean\n",
    "        self.layers.append(dglnn.SAGEConv(in_size, hid_size, \"mean\"))\n",
    "        self.layers.append(dglnn.SAGEConv(hid_size, hid_size, \"mean\"))\n",
    "        self.layers.append(dglnn.SAGEConv(hid_size, hid_size, \"mean\"))\n",
    "        self.hid_size = hid_size\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hid_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, pair_graph, neg_pair_graph, blocks, x):\n",
    "        h = x\n",
    "        for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
    "            h = layer(block, h)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = F.relu(h)\n",
    "        pos_src, pos_dst = pair_graph.edges()\n",
    "        neg_src, neg_dst = neg_pair_graph.edges()\n",
    "        h_pos = self.predictor(h[pos_src] * h[pos_dst])\n",
    "        h_neg = self.predictor(h[neg_src] * h[neg_dst])\n",
    "        return h_pos, h_neg\n",
    "\n",
    "    def inference(self, g, device, batch_size):\n",
    "        \"\"\"Layer-wise inference algorithm to compute GNN node embeddings.\"\"\"\n",
    "        feat = g.ndata[\"feat\"]\n",
    "        sampler = MultiLayerFullNeighborSampler(1, prefetch_node_feats=[\"feat\"])\n",
    "        dataloader = DataLoader(\n",
    "            g,\n",
    "            torch.arange(g.num_nodes()).to(g.device),\n",
    "            sampler,\n",
    "            device=device,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=0,\n",
    "        )\n",
    "        buffer_device = torch.device(\"cpu\")\n",
    "        pin_memory = buffer_device != device\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            y = torch.empty(\n",
    "                g.num_nodes(),\n",
    "                self.hid_size,\n",
    "                device=buffer_device,\n",
    "                pin_memory=pin_memory,\n",
    "            )\n",
    "            feat = feat.to(device)\n",
    "            for input_nodes, output_nodes, blocks in tqdm.tqdm(\n",
    "                dataloader, desc=\"Inference\"\n",
    "            ):\n",
    "                x = feat[input_nodes]\n",
    "                h = layer(blocks[0], x)\n",
    "                if l != len(self.layers) - 1:\n",
    "                    h = F.relu(h)\n",
    "                y[output_nodes] = h.to(buffer_device)\n",
    "            feat = y\n",
    "        return y\n",
    "\n",
    "\n",
    "def compute_mrr(\n",
    "    model, evaluator, node_emb, src, dst, neg_dst, device, batch_size=500\n",
    "):\n",
    "    \"\"\"Compute Mean Reciprocal Rank (MRR) in batches.\"\"\"\n",
    "    rr = torch.zeros(src.shape[0])\n",
    "    for start in tqdm.trange(0, src.shape[0], batch_size, desc=\"Evaluate\"):\n",
    "        end = min(start + batch_size, src.shape[0])\n",
    "        all_dst = torch.cat([dst[start:end, None], neg_dst[start:end]], 1)\n",
    "        h_src = node_emb[src[start:end]][:, None, :].to(device)\n",
    "        h_dst = node_emb[all_dst.view(-1)].view(*all_dst.shape, -1).to(device)\n",
    "        pred = model.predictor(h_src * h_dst).squeeze(-1)\n",
    "        input_dict = {\"y_pred_pos\": pred[:, 0], \"y_pred_neg\": pred[:, 1:]}\n",
    "        rr[start:end] = evaluator.eval(input_dict)[\"mrr_list\"]\n",
    "    return rr.mean()\n",
    "\n",
    "\n",
    "def evaluate(device, graph, edge_split, model, batch_size):\n",
    "    model.eval()\n",
    "    evaluator = Evaluator(name=\"ogbl-citation2\")\n",
    "    with torch.no_grad():\n",
    "        node_emb = model.inference(graph, device, batch_size)\n",
    "        results = []\n",
    "        for split in [\"valid\", \"test\"]:\n",
    "            src = edge_split[split][\"source_node\"].to(node_emb.device)\n",
    "            dst = edge_split[split][\"target_node\"].to(node_emb.device)\n",
    "            neg_dst = edge_split[split][\"target_node_neg\"].to(node_emb.device)\n",
    "            results.append(\n",
    "                compute_mrr(\n",
    "                    model, evaluator, node_emb, src, dst, neg_dst, device\n",
    "                )\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = DglLinkPropPredDataset(\"ogbl-citation2\",root=\"/raid/bear/raw_dataset\")\n",
    "#dataset = DglLinkPropPredDataset(\"ogbl-ppa\",root=\"/home/bear/workspace/single-gnn/data/dataset\")\n",
    "dataset = DglLinkPropPredDataset(\"ogbl-vessel\",root=\"/home/bear/workspace/single-gnn/data/dataset\")\n",
    "g = dataset[0]\n",
    "# g, reverse_eids = to_bidirected_with_reverse_mapping(g)\n",
    "# edge_split = dataset.get_edge_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata['feat'] = g.ndata['feat'].to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=3538495, num_edges=8553438,\n",
       "      ndata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)}\n",
       "      edata_schemes={'count': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, g, reverse_eids, seed_edges, model):\n",
    "    # create sampler & dataloader\n",
    "    sampler = NeighborSampler([5, 5, 5], prefetch_node_feats=[\"feat\"])\n",
    "    sampler = as_edge_prediction_sampler(\n",
    "        sampler,\n",
    "        exclude=\"reverse_id\",\n",
    "        reverse_eids=reverse_eids,\n",
    "        negative_sampler=negative_sampler.Uniform(1),\n",
    "    )\n",
    "    use_uva = True\n",
    "    dataloader = DataLoader(\n",
    "        g,\n",
    "        seed_edges,\n",
    "        sampler,\n",
    "        device=device,\n",
    "        batch_size=512,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=0,\n",
    "        use_uva=use_uva,\n",
    "    )\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for it, (input_nodes, pair_graph, neg_pair_graph, blocks) in enumerate(\n",
    "            dataloader\n",
    "        ):\n",
    "            x = blocks[0].srcdata[\"feat\"]\n",
    "            pos_score, neg_score = model(pair_graph, neg_pair_graph, blocks, x)\n",
    "            score = torch.cat([pos_score, neg_score])\n",
    "            pos_label = torch.ones_like(pos_score)\n",
    "            neg_label = torch.zeros_like(neg_score)\n",
    "            labels = torch.cat([pos_label, neg_label])\n",
    "            loss = F.binary_cross_entropy_with_logits(score, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "            if (it + 1) == 1000:\n",
    "                break\n",
    "        print(\"Epoch {:05d} | Loss {:.4f}\".format(epoch, total_loss / (it + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_split = dataset.get_edge_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'edge': tensor([[191305, 261775],\n",
       "          [165310, 359025],\n",
       "          [529367, 543502],\n",
       "          ...,\n",
       "          [537042, 489579],\n",
       "          [301988, 116925],\n",
       "          [207396,  15651]])},\n",
       " 'valid': {'edge': tensor([[145770, 110372],\n",
       "          [426863, 530655],\n",
       "          [361865, 420758],\n",
       "          ...,\n",
       "          [399989, 405159],\n",
       "          [232672, 423416],\n",
       "          [482297, 387720]]),\n",
       "  'edge_neg': tensor([[500507, 173386],\n",
       "          [336022, 229224],\n",
       "          [435382, 429875],\n",
       "          ...,\n",
       "          [475514, 193934],\n",
       "          [442108, 180966],\n",
       "          [169069, 302110]])},\n",
       " 'test': {'edge': tensor([[128708,  40029],\n",
       "          [382938, 479999],\n",
       "          [574051, 120560],\n",
       "          ...,\n",
       "          [449565, 276247],\n",
       "          [209124, 386192],\n",
       "          [245040,  18435]]),\n",
       "  'edge_neg': tensor([[ 26123, 496841],\n",
       "          [326837, 571973],\n",
       "          [ 45005, 474731],\n",
       "          ...,\n",
       "          [ 81731, 201085],\n",
       "          [ 21532, 401107],\n",
       "          [533954, 125366]])}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 00000 | Loss 1061.7316\n",
      "Epoch 00001 | Loss 17.2058\n",
      "Epoch 00002 | Loss 7.7767\n",
      "Epoch 00003 | Loss 4.2840\n",
      "Epoch 00004 | Loss 2.2660\n",
      "Epoch 00005 | Loss 1.8080\n",
      "Epoch 00006 | Loss 1.1944\n",
      "Epoch 00007 | Loss 0.5723\n",
      "Epoch 00008 | Loss 0.4253\n",
      "Epoch 00009 | Loss 0.2472\n",
      "Validation/Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 3539/3539 [00:17<00:00, 207.78it/s]\n",
      "Inference: 100%|██████████| 3539/3539 [00:17<00:00, 207.28it/s]\n",
      "Inference: 100%|██████████| 3539/3539 [00:16<00:00, 209.76it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'source_node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb 单元格 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# validate/test the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation/Testing...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m valid_mrr, test_mrr \u001b[39m=\u001b[39m evaluate(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     device, g, edge_split, model, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mValidation MRR \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Test MRR \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m         valid_mrr\u001b[39m.\u001b[39mitem(), test_mrr\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m )\n",
      "\u001b[1;32m/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb 单元格 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m     src \u001b[39m=\u001b[39m edge_split[split][\u001b[39m\"\u001b[39;49m\u001b[39msource_node\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mto(node_emb\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m     dst \u001b[39m=\u001b[39m edge_split[split][\u001b[39m\"\u001b[39m\u001b[39mtarget_node\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(node_emb\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2256313030227d/home/bear/workspace/single-gnn/src/train/link_pred/raw/lp_graphsage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m     neg_dst \u001b[39m=\u001b[39m edge_split[split][\u001b[39m\"\u001b[39m\u001b[39mtarget_node_neg\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(node_emb\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'source_node'"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\n",
    "#     \"--mode\",\n",
    "#     default=\"mixed\",\n",
    "#     choices=[\"cpu\", \"mixed\", \"puregpu\"],\n",
    "#     help=\"Training mode. 'cpu' for CPU training, 'mixed' for CPU-GPU mixed training, \"\n",
    "#     \"'puregpu' for pure-GPU training.\",\n",
    "# )\n",
    "# args = parser.parse_args()\n",
    "# if not torch.cuda.is_available():\n",
    "#     args.mode = \"cpu\"\n",
    "# print(f\"Training in {args.mode} mode.\")\n",
    "\n",
    "# load and preprocess dataset\n",
    "# print(\"Loading data\")\n",
    "# dataset = DglLinkPropPredDataset(\"ogbl-citation2\",root=\"/home/bear/workspace/singleGNN/data/dataset\")\n",
    "# g = dataset[0]\n",
    "# g = g.to(\"cpu\")\n",
    "\n",
    "# print(g.edges())\n",
    "# exit()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "g, reverse_eids = to_bidirected_with_reverse_mapping(g)\n",
    "reverse_eids = reverse_eids.to(device)\n",
    "seed_edges = torch.arange(g.num_edges()).to(device)\n",
    "edge_split = dataset.get_edge_split()\n",
    "\n",
    "# create GraphSAGE model\n",
    "in_size = g.ndata[\"feat\"].shape[1]\n",
    "model = SAGE(in_size, 256).to(device)\n",
    "\n",
    "# model training\n",
    "print(\"Training...\")\n",
    "train(device, g, reverse_eids, seed_edges, model)\n",
    "\n",
    "# validate/test the model\n",
    "print(\"Validation/Testing...\")\n",
    "valid_mrr, test_mrr = evaluate(\n",
    "    device, g, edge_split, model, batch_size=1000\n",
    ")\n",
    "print(\n",
    "    \"Validation MRR {:.4f}, Test MRR {:.4f}\".format(\n",
    "        valid_mrr.item(), test_mrr.item()\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
