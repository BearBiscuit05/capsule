{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as MF\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "from dgl.data import AsNodePredDataset\n",
    "from dgl.dataloading import DataLoader, NeighborSampler, MultiLayerFullNeighborSampler\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as MF\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "from dgl.data import AsNodePredDataset\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_size, hid_size, out_size,num_layers=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        # three-layer GraphSAGE-mean\n",
    "        self.layers.append(dglnn.SAGEConv(in_size, hid_size, 'mean'))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(dglnn.SAGEConv(hid_size, hid_size, 'mean'))\n",
    "        self.layers.append(dglnn.SAGEConv(hid_size, out_size, 'mean'))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.hid_size = hid_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "    def forward(self, blocks, x):\n",
    "        h = x\n",
    "        for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
    "            h = layer(block, h)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = F.relu(h)\n",
    "                h = self.dropout(h)\n",
    "        return h\n",
    "\n",
    "    def inference(self, g,device, batch_size):\n",
    "        \"\"\"Conduct layer-wise inference to get all the node embeddings.\"\"\"\n",
    "        feat = g.ndata['feat']\n",
    "        sampler = MultiLayerFullNeighborSampler(1, prefetch_node_feats=['feat'])\n",
    "        # sampler = NeighborSampler([15],  # fanout for [layer-0, layer-1, layer-2]\n",
    "        #                     prefetch_node_feats=['feat'],\n",
    "        #                     prefetch_labels=['label'])\n",
    "        dataloader = DataLoader(\n",
    "                g, torch.arange(g.num_nodes()).to(g.device), sampler, device=device,\n",
    "                batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "                num_workers=0)\n",
    "        buffer_device = torch.device('cpu')\n",
    "        pin_memory = (buffer_device != device)\n",
    "\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            y = torch.empty(\n",
    "                g.num_nodes(), self.hid_size if l != len(self.layers) - 1 else self.out_size,\n",
    "                device=buffer_device, pin_memory=pin_memory)\n",
    "            feat = feat.to(device)\n",
    "            for input_nodes, output_nodes, blocks in tqdm.tqdm(dataloader, position=0):\n",
    "                x = feat[input_nodes]\n",
    "                h = layer(blocks[0], x) # len(blocks) = 1\n",
    "                if l != len(self.layers) - 1:\n",
    "                    h = F.relu(h)\n",
    "                    h = self.dropout(h)\n",
    "                # by design, our output nodes are contiguous\n",
    "                y[output_nodes[0]:output_nodes[-1]+1] = h.to(buffer_device)\n",
    "            feat = y\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import pandas\n",
    "import torch\n",
    "import numpy as np\n",
    "path = \"/raid/bear/dataset\" \n",
    "dataset = \"uk-2006-05\" \n",
    "graphbin = \"%s/%s/graph.bin\" % (path,dataset)\n",
    "  \n",
    "labelbin = \"%s/%s/labels.bin\" % (path,dataset) # 每个节点label 8字节\n",
    "featsbin = \"%s/%s/feats_%d.bin\" % (path,dataset,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.fromfile(graphbin,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = edges[::2]\n",
    "dsts = edges[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.graph((srcs, dsts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=77741023, num_edges=2965197340,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77741046, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = np.fromfile(featsbin,dtype=np.float32).reshape(-1,100)\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77741023, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_tmp = feats[:g.num_nodes()]\n",
    "feats_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77741046,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.fromfile(labelbin,dtype=np.int64)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata['feat'] = torch.tensor(feats_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label= label[:77741023]\n",
    "g.ndata['label'] = torch.tensor(label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                           \n",
    "trainnum = int(g.num_nodes() * 0.01)\n",
    "train_idx = np.arange(trainnum,dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      1,      2,  ..., 777407, 777408, 777409])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx = torch.Tensor(train_idx).to(torch.int64)\n",
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NeighborSampler([10,10,10])\n",
    "use_uva = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=77741023, num_edges=2965197340,\n",
       "      ndata_schemes={'feat': Scheme(shape=(100,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77741023"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      1,      2,  ..., 777407, 777408, 777409])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(g, train_idx, sampler, device='cuda',\n",
    "                                  batch_size=16, shuffle=False,\n",
    "                                  drop_last=False, num_workers=0,\n",
    "                                  use_uva=use_uva)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
